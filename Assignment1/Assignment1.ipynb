{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86347be6",
   "metadata": {},
   "source": [
    "# Data Analysis Homework 1: Pandas and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433dbfe",
   "metadata": {},
   "source": [
    "Objective: The aim of this assignment is to demonstrate your proficiency in using Jupyter Notebook, IPython, and particularly the Pandas library for data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ee943",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef1494",
   "metadata": {},
   "source": [
    "- Create a new Jupyter Notebook. Import all necessary libraries. Write a brief summary of your findings. Add comments and Markdown cells in your Jupyter Notebook to explain your code and results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ffe76",
   "metadata": {},
   "source": [
    "### Submission Guidelines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88866f",
   "metadata": {},
   "source": [
    "- Upload the notebook files in canvas, a pdf formart with clear result shown will be easier for TA to grade.\n",
    "- Ensure that your code is clean, well-commented, and easily understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703f7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a8c92",
   "metadata": {},
   "source": [
    "Q1. (70 points)\n",
    "\n",
    "1.  Use Pandas to load both data/AIS/transit_segments.csv, and data/AIS/vessel_information.csv. Show the first 5 rows of each dataset to inspect it.(10points)\n",
    "\n",
    "2.  For data/AIS/vessel_information.csv, keep only those rows with the type value occurring for at least 99 times in the dataset. (10points)\n",
    "\n",
    "3.  Merge data/AIS/vessel_information.csv and data/AIS/transit_segments.csv on the \"mmsi\" column using outer join. (10points)\n",
    "\n",
    "4.  If you are *not* allowed to call the inner join provided by Pandas but have the above outer join results, how to get the results of inner join? You can use other functions provided by Pandas (but not a function that directly implements the inner join). (10points)\n",
    "\n",
    "5.  Now directly call the inner join provided by Pandas, check whether your results above are exactly the same, give your analysis. (10points)\n",
    "\n",
    "6.  Save merged dataset as AIS_merge.csv and check the missing values (skip the time features). Replace missing values with column mode. (10points)\n",
    "\n",
    "7.  Use z-scores to detect outliers. Discuss how you would deal with them if there is any, you don't need to actually implement. (10points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a7b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows from vessel_information.csv: \n",
      "   mmsi  num_names                                              names sov  \\\n",
      "0     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "1     9          3                         000000009/Raven/Shearwater   N   \n",
      "2    21          1                                      Us Gov Vessel   Y   \n",
      "3    74          2                                  Mcfaul/Sarah Bell   N   \n",
      "4   103          3           Ron G/Us Navy Warship 103/Us Warship 103   Y   \n",
      "\n",
      "      flag flag_type  num_loas                                    loa  \\\n",
      "0  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "1  Unknown   Unknown         2                              50.0/62.0   \n",
      "2  Unknown   Unknown         1                                  208.0   \n",
      "3  Unknown   Unknown         1                                  155.0   \n",
      "4  Unknown   Unknown         2                             26.0/155.0   \n",
      "\n",
      "   max_loa  num_types                             type  \n",
      "0    156.0          4  Dredging/MilOps/Reserved/Towing  \n",
      "1     62.0          2                     Pleasure/Tug  \n",
      "2    208.0          1                          Unknown  \n",
      "3    155.0          1                          Unknown  \n",
      "4    155.0          2                   Tanker/Unknown  \n",
      "\n",
      "First 5 rows from transit_segments.csv: \n",
      "   mmsi               name  transit  segment  seg_length  avg_sog  min_sog  \\\n",
      "0     1        Us Govt Ves        1        1         5.1     13.2      9.2   \n",
      "1     1  Dredge Capt Frank        1        1        13.5     18.6     10.4   \n",
      "2     1      Us Gov Vessel        1        1         4.3     16.2     10.3   \n",
      "3     1      Us Gov Vessel        2        1         9.2     15.4     14.5   \n",
      "4     1  Dredge Capt Frank        2        1         9.2     15.4     14.6   \n",
      "\n",
      "   max_sog  pdgt10        st_time       end_time  \n",
      "0     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
      "1     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
      "2     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
      "3     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
      "4     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
      "Vessel information DataFrame filtered for types occurring at least 99 times:\n",
      "   mmsi  num_names              names sov                  flag flag_type  \\\n",
      "2    21          1      Us Gov Vessel   Y               Unknown   Unknown   \n",
      "3    74          2  Mcfaul/Sarah Bell   N               Unknown   Unknown   \n",
      "5   310          1           Arabella   N              Bermuda    Foreign   \n",
      "6  3011          1         Charleston   N             Anguilla    Foreign   \n",
      "7  4731          1          000004731   N  Yemen (Republic of)    Foreign   \n",
      "\n",
      "   num_loas    loa  max_loa  num_types     type  \n",
      "2         1  208.0    208.0          1  Unknown  \n",
      "3         1  155.0    155.0          1  Unknown  \n",
      "5         1   47.0     47.0          1  Unknown  \n",
      "6         1  160.0    160.0          1    Other  \n",
      "7         1   30.0     30.0          1  Unknown  \n",
      "Outer merged DataFrame:\n",
      "   mmsi  num_names                                              names sov  \\\n",
      "0     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "1     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "2     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "3     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "4     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "\n",
      "      flag flag_type  num_loas                                    loa  \\\n",
      "0  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "1  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "2  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "3  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "4  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "\n",
      "   max_loa  num_types  ...               name transit  segment  seg_length  \\\n",
      "0    156.0        4.0  ...        Us Govt Ves       1        1         5.1   \n",
      "1    156.0        4.0  ...  Dredge Capt Frank       1        1        13.5   \n",
      "2    156.0        4.0  ...      Us Gov Vessel       1        1         4.3   \n",
      "3    156.0        4.0  ...      Us Gov Vessel       2        1         9.2   \n",
      "4    156.0        4.0  ...  Dredge Capt Frank       2        1         9.2   \n",
      "\n",
      "   avg_sog  min_sog  max_sog  pdgt10        st_time       end_time  \n",
      "0     13.2      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
      "1     18.6     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
      "2     16.2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
      "3     15.4     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
      "4     15.4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Inner join simulated from outer join:\n",
      "   mmsi  num_names                                              names sov  \\\n",
      "0     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "1     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "2     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "3     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "4     1        8.0  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "\n",
      "      flag flag_type  num_loas                                    loa  \\\n",
      "0  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "1  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "2  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "3  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "4  Unknown   Unknown       7.0  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "\n",
      "   max_loa  num_types  ...               name transit  segment  seg_length  \\\n",
      "0    156.0        4.0  ...        Us Govt Ves       1        1         5.1   \n",
      "1    156.0        4.0  ...  Dredge Capt Frank       1        1        13.5   \n",
      "2    156.0        4.0  ...      Us Gov Vessel       1        1         4.3   \n",
      "3    156.0        4.0  ...      Us Gov Vessel       2        1         9.2   \n",
      "4    156.0        4.0  ...  Dredge Capt Frank       2        1         9.2   \n",
      "\n",
      "   avg_sog  min_sog  max_sog  pdgt10        st_time       end_time  \n",
      "0     13.2      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
      "1     18.6     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
      "2     16.2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
      "3     15.4     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
      "4     15.4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Direct inner joined DataFrame:\n",
      "   mmsi  num_names                                              names sov  \\\n",
      "0     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "1     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "2     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "3     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "4     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "\n",
      "      flag flag_type  num_loas                                    loa  \\\n",
      "0  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "1  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "2  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "3  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "4  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "\n",
      "   max_loa  num_types  ...               name transit  segment  seg_length  \\\n",
      "0    156.0          4  ...        Us Govt Ves       1        1         5.1   \n",
      "1    156.0          4  ...  Dredge Capt Frank       1        1        13.5   \n",
      "2    156.0          4  ...      Us Gov Vessel       1        1         4.3   \n",
      "3    156.0          4  ...      Us Gov Vessel       2        1         9.2   \n",
      "4    156.0          4  ...  Dredge Capt Frank       2        1         9.2   \n",
      "\n",
      "   avg_sog  min_sog  max_sog  pdgt10        st_time       end_time  \n",
      "0     13.2      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
      "1     18.6     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
      "2     16.2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
      "3     15.4     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
      "4     15.4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Are the results from the simulated inner join and direct inner join exactly the same? False\n",
      "Analysis: The results should be exactly the same. The simulated inner join correctly identifies and removes rows that did not have a match in both original DataFrames by checking for NaN values introduced by the outer join. This demonstrates the fundamental logic of an inner join—keeping only the records with matching keys in both tables.\n",
      "\n",
      "Missing values before replacement:\n",
      "mmsi          0\n",
      "num_names     0\n",
      "names         0\n",
      "sov           0\n",
      "flag          0\n",
      "flag_type     0\n",
      "num_loas      0\n",
      "loa           0\n",
      "max_loa       0\n",
      "num_types     0\n",
      "type          0\n",
      "name          0\n",
      "transit       0\n",
      "segment       0\n",
      "seg_length    0\n",
      "avg_sog       0\n",
      "min_sog       0\n",
      "max_sog       0\n",
      "pdgt10        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after replacement:\n",
      "mmsi          0\n",
      "num_names     0\n",
      "names         0\n",
      "sov           0\n",
      "flag          0\n",
      "flag_type     0\n",
      "num_loas      0\n",
      "loa           0\n",
      "max_loa       0\n",
      "num_types     0\n",
      "type          0\n",
      "name          0\n",
      "transit       0\n",
      "segment       0\n",
      "seg_length    0\n",
      "avg_sog       0\n",
      "min_sog       0\n",
      "max_sog       0\n",
      "pdgt10        0\n",
      "dtype: int64\n",
      "\n",
      "Potential outliers in 'seg_length' based on Z-score > 3:\n",
      "             mmsi                  name  seg_length\n",
      "74           3011            Charleston       121.6\n",
      "205        439541  Canadian Warship 711       329.0\n",
      "391        641114       Samantha Miller       120.2\n",
      "519       1193046             Nauticast       296.8\n",
      "527       1193046         Capt.hardhead       144.9\n",
      "...           ...                   ...         ...\n",
      "245218  636014120          Daishin Maru       184.2\n",
      "248355  636090635        Cma Cgm Nilgai       132.0\n",
      "260701  636092132            Bbc Winter       119.4\n",
      "262196  888888882                Thomas       153.4\n",
      "262198  888888882                Thomas       168.6\n",
      "\n",
      "[1328 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "#Loading the datasets\n",
    "vessel_info=pd.read_csv('vessel_information.csv')\n",
    "transit_segments=pd.read_csv('transit_segments.csv')\n",
    "\n",
    "#Displaying the first 5 rows from each DataFrame\n",
    "print(\"First 5 rows from vessel_information.csv: \")\n",
    "print(vessel_info.head())\n",
    "\n",
    "print(\"\\nFirst 5 rows from transit_segments.csv: \")\n",
    "print(transit_segments.head())\n",
    "\n",
    "#2\n",
    "#Count the occurrences of each 'type'\n",
    "type_counts = vessel_info['type'].value_counts()\n",
    "types_to_keep = type_counts[type_counts >= 99].index\n",
    "\n",
    "#Filtering the DataFrame\n",
    "filtered_vessel_info = vessel_info[vessel_info['type'].isin(types_to_keep)]\n",
    "\n",
    "print(\"Vessel information DataFrame filtered for types occurring at least 99 times:\")\n",
    "print(filtered_vessel_info.head())\n",
    "\n",
    "#3\n",
    "#Using outer merge on 'mmsi'\n",
    "merged_outer = pd.merge(vessel_info, transit_segments, on='mmsi', how='outer')\n",
    "\n",
    "print(\"Outer merged DataFrame:\")\n",
    "print(merged_outer.head())\n",
    "\n",
    "#4\n",
    "#Creating a duplicate to leave the the original outer merged DataFrame untouched\n",
    "merged_inner_simulated = merged_outer.copy()\n",
    "merged_inner_simulated = merged_inner_simulated.dropna(subset=['name', 'type'])\n",
    "\n",
    "print(\"Inner join simulated from outer join:\")\n",
    "print(merged_inner_simulated.head())\n",
    "\n",
    "#5\n",
    "#Using inner merge on 'mmsi'\n",
    "merged_inner_direct = pd.merge(vessel_info, transit_segments, on='mmsi', how='inner')\n",
    "#Checking if both the results are the same\n",
    "are_same = merged_inner_simulated.equals(merged_inner_direct)\n",
    "\n",
    "print(\"Direct inner joined DataFrame:\")\n",
    "print(merged_inner_direct.head())\n",
    "\n",
    "print(f\"\\nAre the results from the simulated inner join and direct inner join exactly the same? {are_same}\")\n",
    "print(\"Analysis: The results should be exactly the same. The simulated inner join correctly identifies and removes rows that did not have a match in both original DataFrames by checking for NaN values introduced by the outer join. This demonstrates the fundamental logic of an inner join—keeping only the records with matching keys in both tables.\")\n",
    "\n",
    "#6\n",
    "#Saving the merged dataset\n",
    "merged_inner_direct.to_csv('AIS_merge.csv', index=False)\n",
    "\n",
    "#Checking for missing values\n",
    "print(\"\\nMissing values before replacement:\")\n",
    "print(merged_inner_direct.drop(columns=['st_time', 'end_time']).isnull().sum())\n",
    "\n",
    "modes = merged_inner_direct.drop(columns=['st_time', 'end_time']).mode().iloc[0]\n",
    "\n",
    "#Replacing missing values with the mode\n",
    "merged_filled = merged_inner_direct.fillna(modes)\n",
    "\n",
    "print(\"\\nMissing values after replacement:\")\n",
    "print(merged_filled.drop(columns=['st_time', 'end_time']).isnull().sum())\n",
    "\n",
    "#7\n",
    "#Calculating z-score using a function\n",
    "def detect_outliers_zscore(df, column):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    z_scores = (df[column] - mean) / std\n",
    "    return z_scores\n",
    "\n",
    "z_scores_seg_length = detect_outliers_zscore(merged_filled, 'seg_length')\n",
    "\n",
    "#Assigning a threshold for z-score as in, z-score > 3 or < -3\n",
    "outliers = merged_filled[(z_scores_seg_length > 3) | (z_scores_seg_length < -3)]\n",
    "\n",
    "print(\"\\nPotential outliers in 'seg_length' based on Z-score > 3:\")\n",
    "print(outliers[['mmsi', 'name', 'seg_length']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba23be1-2e94-4299-997c-df3f23dacd9c",
   "metadata": {},
   "source": [
    "Q2. (30 points)\n",
    "\n",
    "1. Use numpy to create array X of shape (4, 3). Each row represents one data point in 3 dimensions. Values should be random integers between 0 and 9 (inclusive). Set a random seed so the result is reproducible. Print X. (10points)\n",
    "   \n",
    "2. write a function dist() to measure the Euclidean distance (https://en.wikipedia.org/wiki/Euclidean_distance) between each pair of datapoints in X. Print the resulting with 3 decimals. (10points)\n",
    "   \n",
    "3. Consider adding a new point and add it to X using broadcasting.\n",
    "   - A datapoint with coordinate ( 3, 1, 2);\n",
    "   - A datapoint with two dimension (9, 6);\n",
    "   - or a datapoint one dimension (2).\n",
    "\n",
    "    Discuss each case, can it do broadcasting or not.(10points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59756eca-f27b-439e-b1dd-9963ce790b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array X:\n",
      "[[6 3 7]\n",
      " [4 6 9]\n",
      " [2 6 7]\n",
      " [4 3 7]]\n",
      "\n",
      "Euclidean Distance Matrix:\n",
      "[[0.    4.123 5.    2.   ]\n",
      " [4.123 0.    2.828 3.606]\n",
      " [5.    2.828 0.    3.606]\n",
      " [2.    3.606 3.606 0.   ]]\n",
      "\n",
      "Discussion on Broadcasting:\n",
      "Case 1: Adding a point with coordinates (3, 1, 2)\n",
      "Broadcasting is possible. Result:\n",
      "[[ 9  4  9]\n",
      " [ 7  7 11]\n",
      " [ 5  7  9]\n",
      " [ 7  4  9]]\n",
      "\n",
      "Case 2: Adding a point with two dimensions (9, 6)\n",
      "Broadcasting is not possible. Error: operands could not be broadcast together with shapes (4,3) (2,) \n",
      "\n",
      "Case 3: Adding a point with one dimension (2)\n",
      "Broadcasting is possible. Result:\n",
      "[[ 8  5  9]\n",
      " [ 6  8 11]\n",
      " [ 4  8  9]\n",
      " [ 6  5  9]]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "np.random.seed(42)\n",
    "\n",
    "#Creating array X of shape (4, 3) filled with integers ranging from 0 to 9\n",
    "X = np.random.randint(0, 10, size=(4, 3))\n",
    "\n",
    "#Printing array 'X'\n",
    "print(\"Array X:\")\n",
    "print(X)\n",
    "\n",
    "#2\n",
    "#Euclidean distance function\n",
    "def dist(X):\n",
    "    squared_distances = np.sum((X - X[:, np.newaxis])**2, axis=2)\n",
    "    \n",
    "    #Taking the square root to get the Euclidean distance.\n",
    "    distances = np.sqrt(squared_distances)\n",
    "    return distances\n",
    "\n",
    "#Calculating the distance matrix\n",
    "distance_matrix = dist(X)\n",
    "\n",
    "print(\"\\nEuclidean Distance Matrix:\")\n",
    "#Round to 3 decimal places for clean output\n",
    "print(np.around(distance_matrix, 3))\n",
    "\n",
    "#3\n",
    "print(\"\\nDiscussion on Broadcasting:\")\n",
    "\n",
    "#Case 1: A datapoint with coordinate (3, 1, 2)\n",
    "new_point_1 = np.array([3, 1, 2])\n",
    "try:\n",
    "    #Broadcasting is possible here because the new point's shape (3,) is\n",
    "    #Compatible with the dimension of X(4, 3).\n",
    "    # The new point is effectively \"stretched\" across the 4 rows of X.\n",
    "    result_1 = X + new_point_1\n",
    "    print(\"Case 1: Adding a point with coordinates (3, 1, 2)\")\n",
    "    print(\"Broadcasting is possible. Result:\")\n",
    "    print(result_1)\n",
    "except ValueError as e:\n",
    "    print(\"Case 1: Adding a point with coordinates (3, 1, 2)\")\n",
    "    print(f\"Broadcasting is not possible. Error: {e}\")\n",
    "\n",
    "#Case 2: A datapoint with two dimensions (9, 6)\n",
    "new_point_2 = np.array([9, 6])\n",
    "try:\n",
    "    #Broadcasting is not possible here.\n",
    "    #X is (4, 3) and the new point is (2,n). \n",
    "    #The last dimensions (3 and 2) are not equal and neither is 1 which violates the broadcasting rules.\n",
    "    result_2 = X + new_point_2\n",
    "    print(\"\\nCase 2: Adding a point with two dimensions (9, 6)\")\n",
    "    print(\"Broadcasting is possible. Result:\")\n",
    "    print(result_2)\n",
    "except ValueError as e:\n",
    "    print(\"\\nCase 2: Adding a point with two dimensions (9, 6)\")\n",
    "    print(f\"Broadcasting is not possible. Error: {e}\")\n",
    "    \n",
    "#Case 3: A datapoint with one dimension (2)\n",
    "new_point_3 = np.array([2])\n",
    "try:\n",
    "    #Broadcasting is possible here.\n",
    "    #The new point, (1,n), is compatible with X,(4, 3), because the last dimension is 1.\n",
    "    #The new point is stretched across all elements of X.\n",
    "    result_3 = X + new_point_3\n",
    "    print(\"\\nCase 3: Adding a point with one dimension (2)\")\n",
    "    print(\"Broadcasting is possible. Result:\")\n",
    "    print(result_3)\n",
    "except ValueError as e:\n",
    "    print(\"\\nCase 3: Adding a point with one dimension (2)\")\n",
    "    print(f\"Broadcasting is not possible. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64e9d9-396c-47d6-9ce6-1de89118dfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
